# DeepLearning
深度学习练习仓库

# 未完成代码教程

https://adaning.github.io/posts/63679.html

传统神经网络：ResNEt、VGG等

词向量技术：word2Vec的cbow、
Seq2Seq 传统上基于 RNN/LSTM/GRU，而 Transformer 完全基于 Attention 机制。
TransFormer

创新点：
1. bert位置编码的层次分解L：
https://kexue.fm/archives/7947
https://xiaosheng.blog/2021/05/30/transformer-position-encoding#%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF
2. 泛化性
https://xiaosheng.blog/2020/06/16/talking-about-generalization